# üîÑ Redund√¢ncia de Arquivos com Azure Data Factory

## üìå Descri√ß√£o do Projeto

Projeto pr√°tico com foco na cria√ß√£o de um processo completo de redund√¢ncia de arquivos usando o Microsoft Azure. O objetivo foi transferir dados de um banco SQL on-premises para o Azure Data Lake, convertendo-os em arquivos `.TXT` organizados por camadas (raw/bronze), utilizando o **Azure Data Factory**.

## üõ†Ô∏è Tecnologias e Servi√ßos Utilizados

- Azure Data Factory  
- SQL Server (on-premises e Azure SQL)  
- Azure Blob Storage  
- Integration Runtime  
- Azure Data Lake  

## üîß O que foi feito

1. Cria√ß√£o da infraestrutura no Azure  
2. Configura√ß√£o do Integration Runtime para conectar com o SQL on-premises  
3. Cria√ß√£o dos **Linked Services** para acesso ao SQL e Blob Storage  
4. Defini√ß√£o dos **Datasets** para as tabelas e arquivos  
5. Desenvolvimento dos **Pipelines** de extra√ß√£o, transforma√ß√£o e carregamento (ETL)  
6. Armazenamento de arquivos `.TXT` por camadas: raw/bronze  
7. Valida√ß√£o, execu√ß√£o e an√°lise de performance dos pipelines  

## üì∑ Prints

> *(Adicione aqui imagens do seu ambiente Azure Data Factory, pipeline criado, execu√ß√£o, e visualiza√ß√£o no Blob Storage)*

## üí° Aprendizados e Insights

- Compreendi a import√¢ncia de estruturar pipelines reutiliz√°veis e bem documentados.
- Aprendi como configurar conex√µes seguras entre ambientes locais e a nuvem.
- Entendi o conceito de camadas (raw, bronze, silver, gold) em arquiteturas de dados modernas.
- Reforcei boas pr√°ticas de ETL com foco em performance e organiza√ß√£o.

## üöÄ Possibilidades Futuras

- Implementar camada **Silver** com dados tratados.  
- Automatizar execu√ß√µes com base em triggers.  
- Aplicar valida√ß√µes mais avan√ßadas e logging com Azure Monitor.  
- Integrar com ferramentas de visualiza√ß√£o como Power BI.
